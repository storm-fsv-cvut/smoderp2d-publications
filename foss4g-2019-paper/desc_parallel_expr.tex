\subsection{Parallel computing experiments}

Because one of the most crucial points of SMODERP2D computations is
the speed, an experimental branch allowing (both CPU and GPU-based)
parallelised computations has been developed.

The main step was to rewrite all loop-based computations into
matrix-based mathematical operations. To keep matrices as so-called
tensors and to perform all the operations, an open source Python
%% TODO: Ondra
library TensorFlow developed by Google Brain Team was used \cite{xxx}.
Even though TensorFlow is most widely used for machine learning and
its performance on basic mathematical operations is not always better
than the one of NumPy, it had been preferred for its easy switch
between CPU and GPU-based core (it depends only on the version of
TensorFlow the user has installed, no needs for changes in code) and
therefore support also for users without an access to machines with
GPU. Another advantage of TensorFlow is its usage of so-called
graphs. A graph is a representation of all operations in
dataflow/workflow and its individual operations are automatically sent
to multiple cores in a CPU or multiple threads in a GPU. These nodes
are run independently in parallel.

To support further development of TensorFlow and exploit its bleeding
edge functionalities, TensorFlow 2.0, which is published currently
just as an alpha version, was used in the SMODERP2D experimental
branch. Because TensorFlow 2.0 is still not suitable with all the
Python acrobatic tricks, NumPy was used for matrix operations in
places where TensorFlow could not (on places where loops were still
needed; looping through a NumPy array is incomparably faster than
through a Tensor).

This experimental SMODERP2D branch is still under development;
however, the alpha-version is ready to be used. The following table
presents the results of different tests made on this version:

%% TODO: Ondra
TODO

\begin{table}[h]
  \centering
  \begin{tabular}{|l|c|c|}\hline
    Setting&\multicolumn{2}{c|}{A4 size paper}\\\hline
    &mm&inches\\
    Top&25&1.0\\
    Bottom&25&1.0\\
    Left&20&0.8\\
    Right&20&0.8\\
    Column Width&82&3.2\\
    Column Spacing&6&0.25\\\hline
  \end{tabular}
  \caption{Margin settings for A4 size paper}
  \label{tab:Margin_settings}
\end{table}

\subsubsection{Further ideas for a basins-based parallel computing}
Besides the GPU-based parallelization (with TensorFlow \cite{xxx} or NVIDIA Cuda technology~\cite{Kalyanapu2011,Le2015}) the CPU-parallelization may also bring good improvement in the computation time reduction. The computation domain is separated into sub-domain based on certain algorithm were each sub-domain is loaded to single cpu core. The domain may be separated into sub-domain with equal area based on a defined grid. It is beneficial to incorporate also hydrological behavior  in the parallelization strategy. In~\cite{Vivoni2011} the basins was separated in sub-basins based on stream network. The sub-basins communicated with co called ghost sell with each other where the water flowed between sub-basins. The strategy aimed to generate as less ghost cells as possible~\cite{Vivoni2011}.

The parallelization strategy outlined in the manuscript is based on the hydrological reality and it is depicted in a simplified setup in the Figure~\ref{fig:cpu-parallel}. The strategy main goal is to reduce the communication CPU-cores during the computation as much as possible. The whole basin is divided into several sub-basins based on the digital elevation model. Outlet of each sub-basin is depicted with red dots in the Figure~\ref{fig:cpu-parallel}. After the sub-basins are defined an order in which to be computed is defined as follows. Sub-basins which are hydrologically the farthest from the basin outlet and therefore have no inflow flow upslope catchments are calculated at first. Those sub-basins have the rainfall recorded in hyetograph as the only input. In the simplified setup shown in the Figure~\ref{fig:cpu-parallel}, the sub-basins 1, 2, 3, and 6 are calculated at first in parallel. The calculated hydrographs of the sub-basins 1, 2, 3, and 4 are stored in the memory. Sub-basins which has an inflow from sub-basins 1, 2, 3, and 6 are calculated next. It this case it is only the sub-basin 4. In this case the water input in the calculation are, besides the hyetograph, also hydrographs of sub-basins 1 and 3 which flow in the basin 4. This the same manned are calculated sub-basins towards in the outlet. (to be finished).

(add about possible advantages and disadvantages)

\begin{figure}[ht!]
  \begin{center}
    \includegraphics[width=1.0\columnwidth]{figures/smoderp-cpu-parallel.png}
    \caption{Strategy for CPU-parallelization}
    \label{fig:cpu-parallel}
  \end{center}
\end{figure}




